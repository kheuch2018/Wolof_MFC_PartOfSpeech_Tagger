{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wolof_MFCT_PartOfSpeech_Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiPNPP1b3XE3MlHhMOQymY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kheuch2018/Wolof_MFC_PartOfSpeech_Tagger/blob/main/Wolof_MFCT_PartOfSpeech_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlcihCse_8Jn"
      },
      "source": [
        "# Wolof Most Frequent Class Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbUYh5y4jRNF",
        "outputId": "2d1146e2-e847-429d-8eb5-dd18b62aa74b"
      },
      "source": [
        "!pip install pomegranate\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pomegranate in /usr/local/lib/python3.7/dist-packages (0.14.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pomegranate) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pomegranate) (1.20.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from pomegranate) (2.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from pomegranate) (3.13)\n",
            "Requirement already satisfied: joblib>=0.9.0b4 in /usr/local/lib/python3.7/dist-packages (from pomegranate) (1.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->pomegranate) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YorD2KoVYHgM",
        "outputId": "d49d9d13-b9dd-468c-93cb-ca0ae2adce54"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Wolof-WTB/master/wo_wtb-ud-train.conllu\n",
        "!wget https://raw.githubusercontent.com/kheuch2018/NLP_Helper/master/main.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 17:39:16--  https://raw.githubusercontent.com/UniversalDependencies/UD_Wolof-WTB/master/wo_wtb-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1622884 (1.5M) [text/plain]\n",
            "Saving to: ‘wo_wtb-ud-train.conllu’\n",
            "\n",
            "wo_wtb-ud-train.con 100%[===================>]   1.55M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-04-17 17:39:16 (29.3 MB/s) - ‘wo_wtb-ud-train.conllu’ saved [1622884/1622884]\n",
            "\n",
            "--2021-04-17 17:39:16--  https://raw.githubusercontent.com/kheuch2018/NLP_Helper/master/main.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4002 (3.9K) [text/plain]\n",
            "Saving to: ‘main.py’\n",
            "\n",
            "main.py             100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-17 17:39:16 (74.2 MB/s) - ‘main.py’ saved [4002/4002]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FmkjVrtihg6"
      },
      "source": [
        "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
        "%reload_ext autoreload\n",
        "%aimport tests\n",
        "%autoreload 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPGT2dJVSWzz"
      },
      "source": [
        "import numpy as np\n",
        "def process_text(path,new_file):\n",
        "  tags_wolof = set()\n",
        "  f2 = open(new_file,\"w+\")\n",
        "  f3 = open(\"tags_\"+new_file,\"w+\")\n",
        "  f = open(path,\"r\")\n",
        "  for line in f.readlines():\n",
        "    if \"#\" not in line:\n",
        "      arr = line.split(\"\t\")[1:5]\n",
        "      if len(arr)>0 and arr[0] == arr[1] and arr[2] == arr[3]:\n",
        "        f2.write(arr[0]+\"\\t\"+arr[2].upper()+\"\\n\")\n",
        "        tags_wolof.add(arr[2].upper())\n",
        "      elif len(arr)>0:\n",
        "        f2.write(arr[0]+\"\\t\"+arr[2].upper()+\"\\n\")\n",
        "        #f2.write(arr[1]+\"\\t\"+arr[3].upper()+\"\\n\")\n",
        "        tags_wolof.update([arr[2].upper()]) #,arr[3].upper()\n",
        "    elif \"# newdoc_id\" not in line  and \"# text \" not in line :\n",
        "      f2.write(\"\\n\")\n",
        "      f2.write(line.replace(\"# sent_id = \",\"\").replace('\"',\"\"))\n",
        "  for tag in np.unique(list(tags_wolof)):\n",
        "    f3.write(tag+\"\\n\")\n",
        "\n",
        "  f2.write(\"\\n\")\n",
        "  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opzl5mm0TWMg"
      },
      "source": [
        "process_text(\"/content/wo_wtb-ud-train.conllu\",\"processed.txt\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBT4iCJYiB2E"
      },
      "source": [
        "# import python modules -- this cell needs to be run again if you make changes to any of the files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "from itertools import chain\n",
        "from collections import Counter, defaultdict\n",
        "from main import Dataset\n",
        "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwfR7CBZ6y2N",
        "outputId": "eefb1762-df0e-459e-aad1-3c44401baff2"
      },
      "source": [
        "len(data.Y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1188"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5YyLGJij_G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcbfa4ef-a526-4ae7-f14f-494838be23ab"
      },
      "source": [
        "data = Dataset(\"/content/processed.txt\",\"/content/tags_processed.txt\")\n",
        "\n",
        "print(\"There are {} sentences in the corpus.\".format(len(data.sentences)))\n",
        "print(\"There are {} sentences in the training set.\".format(len(data.training_set[\"sentences\"])))\n",
        "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set[\"sentences\"])))\n",
        "\n",
        "assert len(data.sentences) == len(data.training_set[\"sentences\"]) + len(data.testing_set[\"sentences\"]), \\\n",
        "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1188 sentences in the corpus.\n",
            "There are 950 sentences in the training set.\n",
            "There are 238 sentences in the testing set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V994f-QNuFf2"
      },
      "source": [
        "data.sentences_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HLy5rue28oT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H86lZfa4uXni"
      },
      "source": [
        "# Building a Most Frequent Class Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYykpMqQugV7"
      },
      "source": [
        "def pair_counts(sequences_A, sequences_B):\n",
        "    \"\"\"Return a dictionary keyed to each unique value in the first sequence list\n",
        "    that counts the number of occurrences of the corresponding value from the\n",
        "    second sequences list.\n",
        "    \n",
        "    For example, if sequences_A is tags and sequences_B is the corresponding\n",
        "    words, then if 1244 sequences contain the word \"time\" tagged as a NOUN, then\n",
        "    you should return a dictionary such that pair_counts[NOUN][time] == 1244\n",
        "    \"\"\"\n",
        "    A = [\"adj\", \"noun\",\"noun\",\"noun\", \"verb\"]\n",
        "    B = [\"ma\", \"grand\",\"mere\", \"grand\", \"grand\"]\n",
        "\n",
        "    result={}\n",
        "    for wordtup,tagtup in zip(sequences_B,sequences_A):\n",
        "      for word,tag in zip(wordtup,tagtup):\n",
        "        result.setdefault(tag,{}) #[tag][word] = 0\n",
        "        result[tag][word] = 0\n",
        "    for wordtup,tagtup in zip(sequences_B,sequences_A):\n",
        "      for word,tag in zip(wordtup,tagtup):\n",
        "        result[tag][word]+=1    \n",
        "    # TODO: Finish this function!\n",
        "    #raise NotImplementedError\n",
        "    return result\n",
        "\n",
        "# Calculate C(t_i, w_i)\n",
        "emission_counts = pair_counts(data.Y,data.X)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rutI2MH1umKH",
        "outputId": "36eda0d2-ec58-4d35-a828-802c906cf9bf"
      },
      "source": [
        "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
        "from collections import namedtuple\n",
        "\n",
        "FakeState = namedtuple(\"FakeState\", \"name\")\n",
        "\n",
        "class MFCTagger:\n",
        "    # NOTE: You should not need to modify this class or any of its methods\n",
        "    missing = FakeState(name=\"<MISSING>\")\n",
        "    \n",
        "    def __init__(self, table):\n",
        "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
        "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
        "        \n",
        "    def viterbi(self, seq):\n",
        "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
        "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
        "\n",
        "\n",
        "# TODO: calculate the frequency of each tag being assigned to each word (hint: similar, but not\n",
        "# the same as the emission probabilities) and use it to fill the mfc_table\n",
        "\n",
        "word_counts = pair_counts(data.training_set[\"Y\"] ,data.training_set[\"X\"])\n",
        "mfc_table = {} # TODO: YOUR CODE HERE\n",
        "\n",
        "for word in data.training_set[\"vocab\"]:\n",
        "  count_word_max = 0\n",
        "  max_tag = \"\"\n",
        "  for tag in word_counts:\n",
        "    if word in word_counts[tag] and word_counts[tag][word] > count_word_max:\n",
        "      count_word_max = word_counts[tag][word]\n",
        "      max_tag = tag\n",
        "  mfc_table[word] = max_tag\n",
        "\n",
        "# DO NOT MODIFY BELOW THIS LINE\n",
        "mfc_model = MFCTagger(mfc_table) # Create a Most Frequent Class tagger instance\n",
        "assert len(mfc_table) == len(data.training_set[\"vocab\"]), \"\"\n",
        "assert all(k in data.training_set[\"vocab\"] for k in mfc_table.keys()), \"\"\n",
        "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>')\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1U_T4OEv9_l"
      },
      "source": [
        "def replace_unknown(sequence):\n",
        "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
        "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
        "    during computation.\n",
        "    \"\"\"\n",
        "    return [w if w in data.training_set[\"vocab\"] else 'nan' for w in sequence]\n",
        "\n",
        "def simplify_decoding(X, model):\n",
        "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
        "    #print(\"heeeee\",replace_unknown(X))\n",
        "    _, state_path = model.viterbi(replace_unknown(X))\n",
        "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfHWGycAw4zA",
        "outputId": "822bf2e5-5726-4c40-ba78-78f745e47b46"
      },
      "source": [
        "list(data.testing_set[\"keys\"])[:3]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wo_wtb-ud-train_995', 'wo_wtb-ud-train_996', 'wo_wtb-ud-train_997']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWmYOsW_AIhY"
      },
      "source": [
        "# Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGmfLuBOwhAH",
        "outputId": "a5de8a8f-cef7-42fa-ef45-656e5921a207"
      },
      "source": [
        "for key in list(data.testing_set[\"keys\"])[:3]:\n",
        "    print(\"Sentence Key: {}\\n\".format(key))\n",
        "    print(\"Predicted labels:\\n-----------------\")\n",
        "    print(simplify_decoding(data.sentences_dict[key][\"words\"], mfc_model))\n",
        "    print()\n",
        "    print(\"Actual labels:\\n--------------\")\n",
        "    print(data.sentences_dict[key][\"tags\"])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence Key: wo_wtb-ud-train_995\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['ADP', 'NOUN', 'ADP', 'ADV', 'NOUN', 'DET', 'ADV', 'AUX', 'PUNCT']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('ADP', 'ADV', 'ADP', 'NOUN', 'NOUN', 'DET', 'VERB', 'AUX', 'PUNCT')\n",
            "\n",
            "\n",
            "Sentence Key: wo_wtb-ud-train_996\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['NOUN', 'NOUN', 'ADV', 'ADP', 'NUM', 'ADV', 'PUNCT', '_', 'AUX', 'PRON', 'VERB', 'VERB', 'PUNCT', 'ADV', 'ADV', 'VERB', 'CCONJ', 'PROPN', 'ADV', 'PUNCT', 'DET', 'NUM', 'ADV', 'PRON', 'ADV', 'PRON', 'PUNCT', '_', 'AUX', 'PRON', 'ADV', 'DET', 'NOUN', 'PUNCT']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('NOUN', 'PROPN', 'VERB', 'ADP', 'DET', 'NOUN', 'PUNCT', '_', 'AUX', 'PRON', 'VERB', 'VERB', 'PUNCT', 'NUM', 'NOUN', 'VERB', 'ADP', 'PROPN', 'PROPN', 'PUNCT', 'DET', 'NUM', 'NOUN', 'PRON', 'VERB', 'PRON', 'PUNCT', '_', 'AUX', 'PRON', 'VERB', 'DET', 'NOUN', 'PUNCT')\n",
            "\n",
            "\n",
            "Sentence Key: wo_wtb-ud-train_997\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CCONJ', 'PRON', 'PRON', 'AUX', 'VERB', 'VERB', 'AUX', 'PUNCT', 'SCONJ', 'NOUN', 'ADP', 'PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'VERB', 'PUNCT', 'PROPN', 'PRON', '_', 'AUX', 'PRON', 'VERB', 'ADV', 'NOUN', 'PUNCT']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CCONJ', 'PRON', 'PRON', 'AUX', 'VERB', 'VERB', 'AUX', 'PUNCT', 'CCONJ', 'ADP', 'SCONJ', 'PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'VERB', 'PUNCT', 'PROPN', 'PRON', '_', 'AUX', 'PRON', 'VERB', 'NOUN', 'NOUN', 'PUNCT')\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ8UOMCj8ebV"
      },
      "source": [
        "# Evaluate accuracy of MFC Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyPcRMOzwkM7"
      },
      "source": [
        "def accuracy(X, Y, model):\n",
        "    \"\"\"Calculate the prediction accuracy by using the model to decode each sequence\n",
        "    in the input X and comparing the prediction with the true labels in Y.\n",
        "    \n",
        "    The X should be an array whose first dimension is the number of sentences to test,\n",
        "    and each element of the array should be an iterable of the words in the sequence.\n",
        "    The arrays X and Y should have the exact same shape.\n",
        "    \n",
        "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
        "    Y = [(), (), ...]\n",
        "    \"\"\"\n",
        "    correct = total_predictions = 0\n",
        "    for observations, actual_tags in zip(X, Y):\n",
        "        \n",
        "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
        "        # raises an error (for example, if a test sentence contains a word that\n",
        "        # is out of vocabulary for the training set). Any exception counts the\n",
        "        # full sentence as an error (which makes this a conservative estimate).\n",
        "        try:\n",
        "            most_likely_tags = simplify_decoding(observations, model)\n",
        "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
        "        except:\n",
        "            pass\n",
        "        total_predictions += len(observations)\n",
        "    return correct / total_predictions"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rx0rvGJ8iCw",
        "outputId": "eabae118-759b-4e7e-e3dd-159500bcd116"
      },
      "source": [
        "mfc_training_acc = accuracy(data.training_set[\"X\"], data.training_set[\"Y\"], mfc_model)\n",
        "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
        "\n",
        "mfc_testing_acc = accuracy(data.testing_set[\"X\"], data.testing_set[\"Y\"], mfc_model)\n",
        "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n",
        "\n",
        "# assert mfc_training_acc >= 0.955, \"Uh oh. Your MFC accuracy on the training set doesn't look right.\"\n",
        "# assert mfc_testing_acc >= 0.925, \"Uh oh. Your MFC accuracy on the testing set doesn't look right.\"\n",
        "# HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy mfc_model: 92.17%\n",
            "testing accuracy mfc_model: 74.66%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}